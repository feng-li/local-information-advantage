# 股吧数据清洗

## 数据说明

1. 目前服务器中存在两个数据库，第一个是路径`/home1/yqhuang/sentiment_out/`下的帖子，另一个为`MySQL`中的数据，两者共通点为均包括股票基础信息，如`Id`，`reply`，`floor`等；不同的是，前者还包括**帖子的情绪量score**与**发帖者与公司的位置信息(e.g. posterprov, firmprov)**，后者有每个帖子具体的内容**content**；

2. `post`文件夹中存储着**8660**个高回复量、高情绪量的讨论帖，类似于百度贴吧中的一整个帖子，每个帖子由楼主发起其他网友参与回复，这是上次股吧数据检索得到的结果，但是由于严格的筛选条件，面临数据量小带来的问题；

   

## 出现问题

- `MySQL`一共有293个帖子出现损坏，无法正常从sql数据库中读入数据，其中中小板占有近290个；

- sql数据库中只含有content，并没有地域相关信息，若需要筛选地域匹配的股票与yqhuang的结果进行merge是不可避免的；

- 在post中存储的数据为已经筛选好的高回复量帖子，共有8659个，可以作为关键词筛选的切入点

- 原始数据中中小板759，创业板457，深圳511，上海935；在新的从sql中导出的数据里，中小板397，创业板355，深圳472，上海945，可初步判断这是由两种不同的数据方式获得的数据，目前我们以原始数据中的数据量为准，以**post**中数据为关键词检索范围；

  

## 处理思路

1. 关键词抽取。抽取可能透露内幕消息的帖子的关键词，形成关键词列表；

   - 人工查找范围：`post`中**地域匹配**与**回复量高于200**的帖子；

   - 若关键词列表并不理想，依次取消**回复量**与**地域匹配**的限制，扩大搜索范围；
   - 需要函数$get\_post(n)$，$\pmb{n}\in[0, 8659]$，表示查看`post`文件夹下的第$n$支股票；

2. 人工标记被判断为透露内幕消息的帖子；

   - 使用字典来存储，**key**为`<name>_<Id>`，**value**为该回复对应的所有内容；
   - 需要函数`append_post(dict, name, id)`，`dict`为存储的字典，，`name`为帖子的名称，Id为需要添加帖子的Id；

3. 股价预测。判断是否与**步骤2**中对股票利空和利多的判断一致；

   - 将**步骤2**中的帖子爬取前后28+7天的Wind数据，剔除周六周日；

   - 利用**auto-arima**模型对股票未来7天数据预测；

   - 计算是否通过K-检验；

   - 人工判断预测走势与真实走势是否相反，若相反则进行最终结果记录，记录数据在原有的基础上，增加字段`p_value`；

   - 需要函数`download_wind(value)`，`value`为dict中每一个序列，删除周六周日数据，存储名为` <name>_<Id> `； `wind_forecast(name)`读取上一步下载的wind结果，对数据进行预测与k检验，将p_value与预测结果可视化；`write_result(dict, name)`将存储结果记录，`dict`分**利多**与**利空**两个字典，`name`为`<name>_<Id>`的格式；

     

## 处理结果

- 路径`/home1/yqhuang/sentiment_out/`下四个股票板块中**312,977,361**个回复，其中发帖城市与总公司所在城市相同的回复共有**14,831,134**个，占总发帖数的**4.73%**；
- 选择每个股票下论坛中情绪量最极端的**4**个帖子(最高与最低分别2个，存储在`post`文件夹下)，共得到**8660**支帖子，共包含回复4,598,768(1.5%)个，其中发帖城市与总公司所在城市相同的帖子共有**209046**个，地域匹配且回复量高于200的有**198823**个；

- 对地域匹配且回复量高于200的帖子做关键词筛选，`keywords = ['内部', '内幕', '内部消息', '内幕消息', '透露', '偷偷']`，得到**690**条回复；
- 删除这些回复中处于同一只股票下同一天的情况，保证程序不会在Wind上重复爬取数据，最终得到**476**条有效回复；
- 从Wind抓取回复前28天与回复后7天的数据，去除周末数据，利用Python的`auto-arima`函数进行预测，对预测结果可视化，人工鉴别利多与利空的回复；
- 人工鉴别结果得到**34**条利多信息与**23**条利空信息；
